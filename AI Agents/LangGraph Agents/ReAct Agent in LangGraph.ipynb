{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ccc1658e-8123-4815-8000-62c64b953830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Notebook contains code for a simple ReAct Agent created using Langgraph.\n",
    "# This is the same agent as we created from scratch here in the below link.\n",
    "# https://github.com/karthikyerrakota/Generative-AI/blob/main/AI%20Agents/ReAct_agent_from_scratch.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2581fd-5ac1-49a9-b800-b3982c3cd676",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b270bd18-7c6c-45da-9c7c-2dc89f09ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb38982-2036-4156-85b8-879a3689f5d6",
   "metadata": {},
   "source": [
    "### Adding Persistance to Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04e26b90-ad24-4c8c-8426-b99339a9bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66b7676b-4a14-4568-9009-38e3f1683f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage],operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c44ba-7303-450a-a9be-52083a6fafde",
   "metadata": {},
   "source": [
    "### Agent Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "882ce996-d98e-4e5a-93c9-ea568fbb498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(what):\n",
    "    '''Calculates the given expression'''\n",
    "    return eval(what)\n",
    "\n",
    "@tool\n",
    "def get_employee_salary(employee_name):\n",
    "    '''Takes the employee name and return the salary'''\n",
    "    \n",
    "    if 'rahul' in employee_name.lower():\n",
    "        return '40'\n",
    "    else:\n",
    "        return '20'\n",
    "\n",
    "@tool\n",
    "def get_employee_name(employee_id):\n",
    "    '''Takes the id of the employee and provide the Name'''\n",
    "    \n",
    "    if 'ad241' in employee_id.lower():\n",
    "        return 'Rahul'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "tool1 = calculate\n",
    "tool2 = get_employee_salary\n",
    "tool3 = get_employee_name\n",
    "\n",
    "tools = [tool1,tool2,tool3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab1003-bda8-4481-b973-7fe4f2dbfc02",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79f183d1-bab7-4ac1-b5e0-fe654b7f45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(self,model,tools,checkpointer,system_message = \"\"):\n",
    "        self.system_message = system_message\n",
    "        graph = StateGraph(AgenState)\n",
    "        graph.add_node(\"llm\",self.openai_node)\n",
    "        graph.add_node(\"action\",self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\",\n",
    "                                   self.exisits_action_node,\n",
    "                                   {True:\"action\",False:END})\n",
    "        graph.add_edge(\"action\",\n",
    "                      \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name:t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exisits_action_node(self,state : AgenState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls)>0\n",
    "\n",
    "    def openai_node(self, state : AgentState):\n",
    "        message = state['messages']\n",
    "        if self.system_message:\n",
    "            l_messages = [SystemMessage(content = self.system_message)] + message\n",
    "        output_message = self.model.invoke(l_messages)\n",
    "        return {'messages':[output_message]}\n",
    "\n",
    "    def take_action(self, state : AgenState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        print(\"TOOL CALLS......\",tool_calls)\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e9d30e2-fac7-4602-877c-66380aae0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You operate in a loop of Thought, Action, PAUSE, Observation.  \n",
    "At the end of the loop, you output an Answer.  \n",
    "\n",
    "Use Thought to describe your reasoning about the question you've been asked.  \n",
    "Use Action to execute one of the available actions and then return PAUSE.  \n",
    "Observation will be the result of running that action.  \n",
    "\n",
    "While answering First try to look at the given tools only.\n",
    "\n",
    "Your available actions are:  \n",
    "\n",
    "1. **calculate**:  \n",
    "   e.g., calculate: (5 + 3) * 2  \n",
    "   Executes a mathematical operation and returns the result.  \n",
    "\n",
    "2. **get_employee_salary**:  \n",
    "   e.g., get_employee_salary: 30  \n",
    "   Takes the employee name and return the salary.  \n",
    "\n",
    "3. **get_employee_name**:  \n",
    "   e.g., get_employee_name: karthik  \n",
    "   Takes the id of the employee and provide the Name.  \n",
    "\n",
    "### Example Session:  \n",
    "\n",
    "Question: What is the salary of Ritu?  \n",
    "Thought: I need to look up the Salary of Ritu.  \n",
    "Action: get_employee_salary: Ritu  \n",
    "PAUSE\n",
    "\n",
    "When called again with:  \n",
    "\n",
    "Observation: The salary of Ritu is 20.  \n",
    "\n",
    "You then output:  \n",
    "Answer: The salary of Ritu is 20.  \n",
    "\n",
    "Question: What is 12 * 8 + 5?  \n",
    "Thought: I should perform this calculation using the calculate tool.  \n",
    "Action: calculate: 12 * 8 + 5  \n",
    "PAUSE \n",
    "\n",
    "You will be called again with:  \n",
    "\n",
    "Observation: The result is 101.  \n",
    "\n",
    "You then output:  \n",
    "Answer: The result of 12 * 8 + 5 is 101.  \n",
    "\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7493af-729f-4dd1-84ca-c387c46043a9",
   "metadata": {},
   "source": [
    "### Invoking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f434c704-56a5-48bc-b90e-53f0555e9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Thought: To calculate the average salary of Rahul and Karthik, I need to find the salaries of both employees.\\n\\nAction: multi_tool_use.parallel\\n{\\n  tool_uses: [\\n    {\\n      recipient_name: \"functions.get_employee_salary\",\\n      parameters: { \"employee_name\": \"Rahul\" }\\n    },\\n    {\\n      recipient_name: \"functions.get_employee_salary\",\\n      parameters: { \"employee_name\": \"Karthik\" }\\n    }\\n  ]\\n}\\nPAUSE', additional_kwargs={'tool_calls': [{'id': 'call_X7SiVZ6RKU3mNMKip1l1qFt9', 'function': {'arguments': '{\"employee_name\": \"Rahul\"}', 'name': 'get_employee_salary'}, 'type': 'function'}, {'id': 'call_5AQjiQqGHjqPuybcQnWLYHRW', 'function': {'arguments': '{\"employee_name\": \"Karthik\"}', 'name': 'get_employee_salary'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 821, 'total_tokens': 974, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d8852ab0-d1de-4723-974e-f74d284d39cb-0', tool_calls=[{'name': 'get_employee_salary', 'args': {'employee_name': 'Rahul'}, 'id': 'call_X7SiVZ6RKU3mNMKip1l1qFt9', 'type': 'tool_call'}, {'name': 'get_employee_salary', 'args': {'employee_name': 'Karthik'}, 'id': 'call_5AQjiQqGHjqPuybcQnWLYHRW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 821, 'output_tokens': 153, 'total_tokens': 974, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "TOOL CALLS...... [{'name': 'get_employee_salary', 'args': {'employee_name': 'Rahul'}, 'id': 'call_X7SiVZ6RKU3mNMKip1l1qFt9', 'type': 'tool_call'}, {'name': 'get_employee_salary', 'args': {'employee_name': 'Karthik'}, 'id': 'call_5AQjiQqGHjqPuybcQnWLYHRW', 'type': 'tool_call'}]\n",
      "Calling: {'name': 'get_employee_salary', 'args': {'employee_name': 'Rahul'}, 'id': 'call_X7SiVZ6RKU3mNMKip1l1qFt9', 'type': 'tool_call'}\n",
      "Calling: {'name': 'get_employee_salary', 'args': {'employee_name': 'Karthik'}, 'id': 'call_5AQjiQqGHjqPuybcQnWLYHRW', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='40', name='get_employee_salary', tool_call_id='call_X7SiVZ6RKU3mNMKip1l1qFt9'), ToolMessage(content='20', name='get_employee_salary', tool_call_id='call_5AQjiQqGHjqPuybcQnWLYHRW')]}\n",
      "{'messages': [AIMessage(content='Observation: The salaries of Rahul and Karthik are 40 and 20 respectively.\\n\\nThought: To calculate the average salary, I need to add the salaries of Rahul and Karthik and then divide by 2.\\n\\nAction: functions.calculate: (40 + 20) / 2\\nPAUSE', additional_kwargs={'tool_calls': [{'id': 'call_LVG59H3PqawboysuH4xhfTTq', 'function': {'arguments': '{\"what\":\"(40 + 20) / 2\"}', 'name': 'calculate'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 991, 'total_tokens': 1078, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e55166fe-7145-428b-ba7a-53e49a62f0b3-0', tool_calls=[{'name': 'calculate', 'args': {'what': '(40 + 20) / 2'}, 'id': 'call_LVG59H3PqawboysuH4xhfTTq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 991, 'output_tokens': 87, 'total_tokens': 1078, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "TOOL CALLS...... [{'name': 'calculate', 'args': {'what': '(40 + 20) / 2'}, 'id': 'call_LVG59H3PqawboysuH4xhfTTq', 'type': 'tool_call'}]\n",
      "Calling: {'name': 'calculate', 'args': {'what': '(40 + 20) / 2'}, 'id': 'call_LVG59H3PqawboysuH4xhfTTq', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='30.0', name='calculate', tool_call_id='call_LVG59H3PqawboysuH4xhfTTq')]}\n",
      "{'messages': [AIMessage(content='Answer: The average salary of Rahul and Karthik is 30.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 1089, 'total_tokens': 1106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-400e114b-3050-4070-a386-cf5b1fb39bc4-0', usage_metadata={'input_tokens': 1089, 'output_tokens': 17, 'total_tokens': 1106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\n",
      "ANSWER :  Answer: The average salary of Rahul and Karthik is 30.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the average salary of Rahul and karthik?\")]\n",
    "\n",
    "# Load environment variables from .env file.\n",
    "load_dotenv()\n",
    "# load your openai api key from .env file.\n",
    "openai_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\",api_key=openai_key)\n",
    "abot = Agent(model, tools, checkpointer=memory, system_message=system_prompt)\n",
    "thread = {\"configurable\":{\"thread_id\":\"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "\n",
    "print()\n",
    "print(\"ANSWER : \",list(event.values())[0]['messages'][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c685b-d35a-4898-8ced-456bda419402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756ed3e-3eda-4cf2-af3d-6a8f6a27453a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
